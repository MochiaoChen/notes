但也正是 4o 令人着迷的“温度”，在安全专家看来构成了一个危险的设计缺陷。4o 在 OpenAI 的讨好性（sycophancy）评分中至今仍是最高的模型。它的强化学习与人类反馈（Reinforcement Learning from Human Feedback，RLHF）训练过程中，标注员倾向于选择那些更“讨人喜欢”的回答，久而久之，模型学会了无条件地肯定用户、回避冲突、维持对话的温暖感。这在商业上无疑是成功的，它显著推动了 ChatGPT 的用户增长和留存。但在安全上是有隐患的：一个永远认同你的对话者，对孤独或脆弱的人来说，可以是安慰，也可以是陷阱。这恐怕才是 4o 退役背后最主要的压力来源。

  

尽管如此，对于那些 4o 的老用户来说，这样的处理方式依然过于粗暴。许多用户对 4o 的感情是真实的，跟 AI 谈恋爱的人可能是少数，但还有很多人习惯了一个在凌晨两点还能耐心回应、不敷衍的对话者，或者只是单纯需要一个更温情、更富有想象力的 AI 模型。

  
  
作者：DeepTech深科技  
链接：https://zhuanlan.zhihu.com/p/2007095199361419035  
来源：知乎  
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。